#!/usr/bin/env bash
# wt-hook-memory-save - Claude Code Stop hook for automatic memory saving
#
# Called by Claude Code after every response (Stop event).
# Two independent extraction paths:
#   1. Commit-based: extracts **Choice** lines from design.md after git commits
#   2. Transcript-based: when opsx/openspec skills were active, uses haiku LLM
#      to extract session insights (errors, learnings, user corrections, patterns)
#
# Designed to be referenced by name in .claude/settings.json:
#   "Stop": [{"matcher": "", "hooks": [{"type": "command", "command": "wt-hook-memory-save", "timeout": 30}]}]
# The script is on PATH via install.sh symlink.

# --- Task 1.1: Parse stdin JSON ---
INPUT=$(cat)

TRANSCRIPT_PATH=$(echo "$INPUT" | python3 -c "import sys,json; print(json.load(sys.stdin).get('transcript_path',''))" 2>/dev/null)
STOP_ACTIVE=$(echo "$INPUT" | python3 -c "import sys,json; print(json.load(sys.stdin).get('stop_hook_active',False))" 2>/dev/null)

# --- Task 1.2: Stop hook active guard ---
if [[ "$STOP_ACTIVE" == "True" || "$STOP_ACTIVE" == "true" ]]; then
    exit 0
fi

# Only run if wt-memory is available and healthy
command -v wt-memory &>/dev/null || exit 0
wt-memory health &>/dev/null || exit 0

mkdir -p .wt-tools

# ============================================================
# PATH 1: Transcript-based extraction (opsx/openspec skills)
# ============================================================

extract_from_transcript() {
    local transcript="$1"
    local transcript_id
    transcript_id=$(basename "$transcript" .jsonl)
    local staged_file=".wt-tools/.staged-extract-${transcript_id}"
    local ts_file="${staged_file}.ts"

    # --- Task 2.1: Detect opsx/openspec skills in transcript ---
    if [[ ! -f "$transcript" ]]; then
        return 1
    fi

    local skill_lines
    skill_lines=$(grep -o '"skill":"opsx:[^"]*"\|"skill":"openspec-[^"]*"' "$transcript" 2>/dev/null)
    if [[ -z "$skill_lines" ]]; then
        return 1  # No opsx/openspec skills found
    fi

    # --- Task 2.2: Extract change names from skill invocations ---
    # Find lines with Skill tool_use and extract args field
    local change_names
    change_names=$(python3 -c "
import json, sys
names = set()
with open('$transcript') as f:
    for line in f:
        try:
            obj = json.loads(line)
            if obj.get('type') != 'assistant': continue
            for block in (obj.get('message',{}).get('content',[]) or []):
                if not isinstance(block, dict): continue
                if block.get('type') == 'tool_use' and block.get('name') == 'Skill':
                    inp = block.get('input',{})
                    skill = inp.get('skill','')
                    if 'opsx:' in skill or 'openspec-' in skill:
                        args = inp.get('args','').strip()
                        if args:
                            names.add(args.split()[0])  # first word = change name
        except: pass
print(','.join(sorted(names)[:5]) if names else '')
" 2>/dev/null)

    # Fallback: extract from skill names if no change names found
    if [[ -z "$change_names" ]]; then
        change_names=$(echo "$skill_lines" \
            | sed 's/.*"skill":"//;s/".*//' \
            | sort -u \
            | head -3 \
            | tr '\n' ',' \
            | sed 's/,$//')
    fi

    # --- Debounce: skip if extracted recently ---
    if [[ -f "$ts_file" ]]; then
        local last_extract_ts
        last_extract_ts=$(cat "$ts_file" 2>/dev/null)
        local now_ts
        now_ts=$(date +%s)
        if [[ -n "$last_extract_ts" ]] && (( now_ts - last_extract_ts < 300 )); then
            echo "[$(date '+%Y-%m-%d %H:%M:%S')] [DEBOUNCE] Skipped extraction for $transcript_id ($(( now_ts - last_extract_ts ))s since last)" >> "$LOG_FILE"
            return 0
        fi
    fi

    # --- Pre-process transcript: extract meaningful content, check dedup ---
    # This reduces ~280KB raw JSONL to ~3-8KB of meaningful text,
    # cutting haiku cost from ~$0.10 to ~$0.002 per invocation.
    # Also fixes dedup: only checks assistant messages for [Memory saved:],
    # not skill prompt text which contains the instruction string.
    local tmpfile
    tmpfile=$(mktemp)
    local agent_saved
    agent_saved=$(python3 << PYEOF
import json, sys

transcript_path = "$transcript"
entries = []
agent_saved = False

with open(transcript_path) as f:
    for line in f:
        try:
            obj = json.loads(line)
            t = obj.get('type', '')

            if t == 'user':
                msg = obj.get('message', {})
                content = msg.get('content', '')
                if isinstance(content, str) and len(content) < 2000:
                    # Skip skill prompt expansions (very long user messages)
                    # and system-reminder tags
                    if '<system-reminder>' not in content and len(content) > 5:
                        entries.append(f"USER: {content[:500]}")

            elif t == 'assistant':
                msg = obj.get('message', {})
                content = msg.get('content', [])
                if isinstance(content, list):
                    for block in content:
                        if not isinstance(block, dict):
                            continue
                        if block.get('type') == 'text':
                            text = block.get('text', '')
                            if text:
                                # Check dedup: did agent actually save memories?
                                if '[Memory saved:' in text or '[Agent insights saved:' in text:
                                    agent_saved = True
                                entries.append(f"AGENT: {text[:500]}")
                        elif block.get('type') == 'tool_use':
                            name = block.get('name', '')
                            inp = block.get('input', {})
                            if name == 'Bash':
                                cmd = inp.get('command', '')[:200]
                                entries.append(f"TOOL[Bash]: {cmd}")

            elif t == 'tool_result':
                # Only capture errors (short) — skip large file contents
                content = obj.get('content', '')
                if isinstance(content, str) and ('error' in content.lower() or 'Error' in content) and len(content) < 1000:
                    entries.append(f"ERROR: {content[:500]}")

        except:
            pass

# Output last ~80 meaningful entries (not raw JSONL lines)
for entry in entries[-80:]:
    print(entry)

# Signal dedup status on the last line
print(f"__AGENT_SAVED__:{agent_saved}")
PYEOF
)

    # Extract dedup flag from pre-processor output
    local dedup_flag
    dedup_flag=$(echo "$agent_saved" | tail -1)
    # Write transcript content (without the flag line) to tmpfile
    echo "$agent_saved" | head -n -1 > "$tmpfile"

    local agent_did_save=false
    if [[ "$dedup_flag" == *"True"* ]]; then
        agent_did_save=true
    fi

    # Check if pre-processed content is meaningful (at least a few entries)
    local line_count
    line_count=$(wc -l < "$tmpfile")
    if [[ "$line_count" -lt 3 ]]; then
        return 0  # Too little content to extract from
    fi

    # --- Extract first change name for tagging ---
    local first_change=""
    if [[ -n "$change_names" ]]; then
        first_change="${change_names%%,*}"  # first entry before comma
    fi

    # --- Build extraction prompt ---
    local dedup_note=""
    if [[ "$agent_did_save" == "true" ]]; then
        dedup_note="NOTE: The agent already saved some memories during this session. Only extract insights the agent likely MISSED — focus on errors, user corrections, and non-obvious discoveries that weren't explicitly saved."
    fi

    local prompt
    prompt="You are a memory extraction system. Analyze this Claude Code session summary and extract valuable insights for future sessions.

$dedup_note

Skills used: $skill_lines
Change names: $change_names

Extract ONLY insights that a future agent in a DIFFERENT session would benefit from knowing:
- Errors encountered and their fixes/workarounds
- User corrections or knowledge shared (in any language)
- Non-obvious patterns or gotchas discovered
- Important decisions or preferences stated by the user

Do NOT extract:
- Routine task completions
- General knowledge any developer would know
- Session-specific context (file paths read, commands run)
- Things that are obvious from reading the code

Output format: one insight per line, format: Type|tags|content
- Type: Learning, Decision, or Context
- tags: comma-separated (e.g., error,change-name or preference,workflow)
- content: concise description (max 200 chars)

Maximum 5 insights. If nothing is worth saving, output exactly: NONE

ALSO extract cross-cutting conventions established in this session — patterns that ALL future changes must follow.
Examples: 'use formatPrice() for all price display', 'all list endpoints return { data, total, page, limit }', 'filter deletedAt IS NULL in all product queries'.
Output conventions as: Convention|tags|content (max 2 conventions)
Only extract conventions if the session clearly establishes a reusable pattern. Do NOT fabricate conventions.

Example output:
Learning|error,shopping-cart|Stock decrement failed silently when variant.stockQuantity was null — added null check
Decision|preference,workflow|User prefers Hungarian commit messages with English code comments
Convention|product-catalog,formatting|All price display must use formatPrice() from src/lib/formatPrice.ts — never use inline .toFixed()

Session summary:"

    # --- Call claude CLI with haiku ---
    local llm_output
    llm_output=$( (echo "$prompt"; echo ""; cat "$tmpfile") | CLAUDECODE= claude -p --model haiku --no-session-persistence 2>/dev/null)

    # --- Task 4.4: Handle failure/timeout/empty ---
    if [[ -z "$llm_output" ]]; then
        return 1
    fi

    if [[ "$llm_output" == "NONE" ]]; then
        return 0
    fi

    # --- Write to staging file (atomic) ---
    local staging_tmp
    staging_tmp=$(mktemp)
    # Header line with change name for commit-time tagging
    echo "#CHANGE:${first_change}" > "$staging_tmp"
    echo "$llm_output" >> "$staging_tmp"
    mv "$staging_tmp" "$staged_file"

    # Write debounce timestamp
    date +%s > "$ts_file"

    # Cleanup preprocessed tmpfile
    rm -f "$tmpfile"

    return 0
}

# ============================================================
# Commit staged extractions from previous sessions
# ============================================================

commit_staged_files() {
    local current_transcript_id="$1"
    local now
    now=$(date +%s)
    local stale_threshold=3600  # 1 hour

    for staged in .wt-tools/.staged-extract-*; do
        [[ -f "$staged" ]] || continue
        [[ "$staged" == *.ts ]] && continue  # Skip timestamp files

        local staged_id
        staged_id=$(basename "$staged" | sed 's/^\.staged-extract-//')
        local ts_file="${staged}.ts"

        # Skip current transcript UNLESS stale
        if [[ "$staged_id" == "$current_transcript_id" ]]; then
            local file_age=0
            if [[ -f "$ts_file" ]]; then
                local last_ts
                last_ts=$(cat "$ts_file" 2>/dev/null)
                [[ -n "$last_ts" ]] && file_age=$(( now - last_ts ))
            else
                # Fallback to file mtime (Linux stat -c, macOS stat -f)
                local mtime
                mtime=$(stat -c %Y "$staged" 2>/dev/null || stat -f %m "$staged" 2>/dev/null)
                [[ -n "$mtime" ]] && file_age=$(( now - mtime ))
            fi

            if (( file_age < stale_threshold )); then
                continue  # Not stale, skip current session's file
            fi
            echo "[$(date '+%Y-%m-%d %H:%M:%S')] [STALE] Committing stale staged file: $staged_id (${file_age}s old)" >> "$LOG_FILE"
        fi

        # Read change name from header
        local first_change=""
        local first_line
        first_line=$(head -1 "$staged")
        if [[ "$first_line" == "#CHANGE:"* ]]; then
            first_change="${first_line#\#CHANGE:}"
        fi

        # Parse and commit insights to wt-memory
        local count=0
        local conv_count=0
        while IFS= read -r line; do
            [[ -z "$line" ]] && continue
            [[ "$line" == "NONE" ]] && continue
            [[ "$line" == "#CHANGE:"* ]] && continue  # Skip header

            # Validate format: Type|tags|content
            if [[ "$line" != *"|"*"|"* ]]; then
                continue
            fi

            local mem_type="${line%%|*}"
            local rest="${line#*|}"
            local tags="${rest%%|*}"
            local content="${rest#*|}"

            # Handle Convention type: save as Learning with convention tag, cap at 2
            if [[ "$mem_type" == "Convention" ]]; then
                (( conv_count >= 2 )) && continue
                mem_type="Learning"
                tags="convention,$tags"
                (( conv_count++ ))
            else
                # Cap regular insights at 5
                (( count >= 5 )) && continue

                # Validate type
                case "$mem_type" in
                    Learning|Decision|Context) ;;
                    *) continue ;;
                esac

                (( count++ ))
            fi

            # Skip empty content
            [[ -z "$content" ]] && continue

            # Build tag string with change: prefix if available
            local full_tags="phase:auto-extract,source:hook,$tags"
            if [[ -n "$first_change" ]]; then
                full_tags="change:$first_change,$full_tags"
            fi

            # Save to wt-memory
            echo "$content" | \
                wt-memory remember \
                    --type "$mem_type" \
                    --tags "$full_tags" \
                    2>/dev/null || true

        done < "$staged"

        # Cleanup
        rm -f "$staged" "$ts_file"
        echo "[$(date '+%Y-%m-%d %H:%M:%S')] Committed staged extraction: $staged_id ($count insights, $conv_count conventions)" >> "$LOG_FILE"
    done
}

# ============================================================
# Background wrapper for transcript extraction
# ============================================================

LOCK_FILE=".wt-tools/.transcript-extraction.lock"
LOG_FILE=".wt-tools/transcript-extraction.log"

run_extraction_background() {
    local transcript="$1"
    local transcript_id
    transcript_id=$(basename "$transcript" .jsonl)

    # --- Lockfile: check for concurrent extraction ---
    if [[ -f "$LOCK_FILE" ]]; then
        local existing_pid
        existing_pid=$(cat "$LOCK_FILE" 2>/dev/null)
        if [[ -n "$existing_pid" ]] && kill -0 "$existing_pid" 2>/dev/null; then
            # Active extraction running — skip
            return 0
        fi
        # Stale lock — remove it
        rm -f "$LOCK_FILE"
    fi

    # Take lock (use BASHPID for actual subprocess PID, $$ gives parent)
    echo ${BASHPID:-$$} > "$LOCK_FILE"

    # Cleanup trap for background process (lock + any temp files)
    trap 'rm -f "$LOCK_FILE" /tmp/tmp.wt-extract.* 2>/dev/null' EXIT

    # Commit staged extractions from previous sessions
    commit_staged_files "$transcript_id"

    # Run extraction, log errors with timestamp
    echo "[$(date '+%Y-%m-%d %H:%M:%S')] Starting extraction for: $transcript" >> "$LOG_FILE"
    extract_from_transcript "$transcript" 2>> "$LOG_FILE" || true
    echo "[$(date '+%Y-%m-%d %H:%M:%S')] Extraction complete" >> "$LOG_FILE"

    # Cleanup lock (trap also handles this, belt+suspenders)
    rm -f "$LOCK_FILE"
}

# Run transcript extraction in background if transcript is available
if [[ -n "$TRANSCRIPT_PATH" ]]; then
    # Expand ~ in path
    TRANSCRIPT_PATH="${TRANSCRIPT_PATH/#\~/$HOME}"
    run_extraction_background "$TRANSCRIPT_PATH" &
    disown
fi

# ============================================================
# PATH 2: Commit-based design choice extraction (existing logic)
# ============================================================

# Marker files
MARKER_FILE=".wt-tools/.last-memory-commit"
DESIGN_MARKER=".wt-tools/.saved-designs"

LAST_HASH=""
if [[ -f "$MARKER_FILE" ]]; then
    LAST_HASH=$(cat "$MARKER_FILE" 2>/dev/null)
fi

# Get current HEAD
CURRENT_HASH=$(git rev-parse HEAD 2>/dev/null) || exit 0

# If no change since last check, exit
[[ "$CURRENT_HASH" == "$LAST_HASH" ]] && exit 0

# Get new commits since last check
if [[ -n "$LAST_HASH" ]]; then
    if git cat-file -t "$LAST_HASH" &>/dev/null; then
        COMMITS=$(git log --oneline "$LAST_HASH..HEAD" 2>/dev/null)
    else
        COMMITS=$(git log --oneline -1 2>/dev/null)
    fi
else
    COMMITS=$(git log --oneline -1 2>/dev/null)
fi

# Process each new commit
while IFS= read -r line; do
    [[ -z "$line" ]] && continue
    hash="${line%% *}"
    msg="${line#* }"

    # Extract change name from commit message (format: "change-name: description")
    if [[ "$msg" == *:* ]]; then
        change_name="${msg%%:*}"
    else
        change_name="general"
    fi

    # Fallback: detect change name from openspec/changes/ if commit message gave "general"
    if [[ "$change_name" == "general" ]] && [[ -d "openspec/changes" ]]; then
        for d in openspec/changes/*/; do
            local dname
            dname=$(basename "$d")
            [[ "$dname" == "archive" ]] && continue
            # Use first active change as fallback
            change_name="$dname"
            break
        done
    fi

    # --- Code map safety net (independent of design extraction) ---
    # If agent didn't save a code map, generate one from git diff.
    # This runs for every change name independently, using its own marker.
    CODEMAP_MARKER=".wt-tools/.saved-codemaps"
    touch "$CODEMAP_MARKER"
    if ! grep -qx "$change_name" "$CODEMAP_MARKER" 2>/dev/null; then
        # Check if agent already saved a code map for this change
        has_codemap=$(wt-memory recall "$change_name code map" --limit 1 --mode semantic 2>/dev/null \
            | python3 -c "import sys,json; r=json.load(sys.stdin); print('yes' if any('code-map' in ','.join(m.get('tags',[])) for m in r) else 'no')" 2>/dev/null)

        if [[ "$has_codemap" != "yes" ]]; then
            # Generate code map from files changed across ALL new commits (not just this one)
            all_hashes=$(echo "$COMMITS" | awk '{print $1}')
            changed_files=$(echo "$all_hashes" | while read -r h; do
                [[ -z "$h" ]] && continue
                git diff-tree --no-commit-id --name-only -r "$h" 2>/dev/null
            done \
                | sort -u \
                | grep -vE '(package\.json|package-lock|\.config\.|tsconfig|\.test\.|\.spec\.|__test__)' \
                | head -8 \
                | tr '\n' ', ' \
                | sed 's/,$//')

            if [[ -n "$changed_files" ]]; then
                codemap_content="$change_name code map (auto): $changed_files"
                if [[ ${#codemap_content} -gt 400 ]]; then
                    codemap_content="${codemap_content:0:397}..."
                fi

                echo "$codemap_content" | \
                    wt-memory remember \
                        --type Context \
                        --tags "change:$change_name,phase:apply,source:hook,code-map" \
                        2>/dev/null || true
            fi
        fi

        echo "$change_name" >> "$CODEMAP_MARKER"
    fi

    # --- Design choice extraction (skip if already processed) ---
    touch "$DESIGN_MARKER"
    grep -qx "$change_name" "$DESIGN_MARKER" 2>/dev/null && continue

    # Build ONE concise memory for this change — only if real design choices exist
    design_file="openspec/changes/$change_name/design.md"
    if [[ -f "$design_file" ]]; then
        # Extract only **Choice**: lines, strip markdown, join with ". "
        choices=$(grep '^\*\*Choice\*\*' "$design_file" 2>/dev/null \
            | sed 's/^\*\*Choice\*\*: //' \
            | sed 's/^\*\*Choice\*\*://' \
            | tr '\n' '.' \
            | sed 's/\.\./\. /g; s/\.$//')

        if [[ -n "$choices" ]]; then
            content="$change_name: $choices"

            # Truncate to 300 chars
            if [[ ${#content} -gt 300 ]]; then
                content="${content:0:297}..."
            fi

            # Save single Decision memory
            echo "$content" | \
                wt-memory remember \
                    --type Decision \
                    --tags "change:$change_name,phase:apply,source:hook,decisions" \
                    2>/dev/null || true
        fi
    fi

    # Mark this change as processed (whether or not we saved)
    echo "$change_name" >> "$DESIGN_MARKER"

done <<< "$COMMITS"

# Update marker to current HEAD
echo "$CURRENT_HASH" > "$MARKER_FILE"

exit 0
